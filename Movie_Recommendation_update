# Libraries
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from ast import literal_eval

# Dataset
data = pd.read_csv("C:/Users/Vinay Moond/PycharmProjects/TermProject/movies_metadata.csv", low_memory=False)
credits = pd.read_csv("C:/Users/Vinay Moond/PycharmProjects/TermProject/credits.csv", low_memory=False)
keywords = pd.read_csv("C:/Users/Vinay Moond/PycharmProjects/TermProject/keywords.csv", low_memory=False)

#top rows of data
print('Top Rows of Data: ','\n', data.head())

# Mean of average vote
mean_vote = data['vote_average'].mean()
print('The mean vote across the whole report: ', mean_vote)

# Minimun vote required
min_vote = data['vote_count'].quantile(0.90)
print('The minimum votes required to be listed in the chart: ',min_vote)

# new dataset with qualified movies
movies = data.copy().loc[data['vote_count'] >= min_vote]
print('Size of Movies dataset: ','\n',movies.shape)
print('Size of Original dataset: ','\n',data.shape)

#Weighted Rating Fumction
def WR_function(x, min_vote=min_vote, mean_vote=mean_vote):
    vote_count = x['vote_count']
    vote_avg = x['vote_average']
    return (vote_count/(vote_count+min_vote) * vote_avg) + (min_vote/(min_vote+vote_count) * mean_vote)

# New column defing the weighted rating
movies['WR'] = movies.apply(WR_function, axis=1)
print('Top Rows of Data: ','\n',movies.head())

#Sorting according to WR
movies = movies.sort_values('WR', ascending=False)

#top 15 movies
print('Top 15 Rows of Data: ','\n',movies[['title', 'vote_count', 'vote_average', 'WR']].head(15))

#overview from data
print('Overview from Data: ','\n',movies['overview'].head())

#Replacing NaN with an empty string
movies['overview'] = movies['overview'].fillna('')

#term frequency–inverse document frequency vectorizer object
tfidf = TfidfVectorizer(stop_words='english')

#term frequency–inverse document frequency matrix
t_matrix = tfidf.fit_transform(movies['overview'])
print('Term Frequency–Inverse Document Frequency Matrix: ','\n',t_matrix)

#cosine similarity matrix
c_matrix = linear_kernel(t_matrix, t_matrix)
print('Cosine Similarity Matrix: ','\n',c_matrix)

#reverse map of indices and movie titles
indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()
print('Reverse Map of Indices and Movie Titles: ','\n',indices[:10])

# Recommendation function
def recommendations(title, c_matrix=c_matrix):
    index = indices[title]

    similarity_scores = list(enumerate(c_matrix[index]))

    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)

    similarity_scores = similarity_scores[1:11]

    movies_title = [i[0] for i in similarity_scores]

    return movies['title'].iloc[movies_title]

#trying if recommendation system works
print('Recommendations based on the movie are: ','\n',recommendations('The Godfather'))
